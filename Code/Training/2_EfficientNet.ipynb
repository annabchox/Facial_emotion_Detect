{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c122be01-578d-46c9-b101-c2daa39ba09e",
   "metadata": {},
   "source": [
    "# Pre-Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7f65eb-4976-491f-bd2a-95077a3605e6",
   "metadata": {},
   "source": [
    "In this notebook, pretrained model (EfficientNetV2B0) will be implemented on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b766231-544f-422a-ae40-40722ae67c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Flatten, \n",
    "                                     Conv2D, MaxPooling2D, BatchNormalization, \n",
    "                                     GlobalAveragePooling2D)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import metrics\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from tensorflow.keras.layers.experimental.preprocessing import (RandomFlip, RandomRotation, \n",
    "                                                                RandomZoom, RandomContrast)\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "# Source: https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b96b48c-a439-4967-a44c-5939b471b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing global variables\n",
    "sys.path.append('../../Code/Helper')\n",
    "import helper as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6875ef2c-14de-47f6-b2f0-639dc1d5a062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50499 files belonging to 7 classes.\n",
      "Using 40400 files for training.\n",
      "Found 50499 files belonging to 7 classes.\n",
      "Using 10099 files for validation.\n",
      "Found 7178 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "base_path = '../../Data/Final'\n",
    "w = 48\n",
    "h = 48\n",
    "# Flow from directory\n",
    "# Code modified from: Lesson 8.06-CNN\n",
    "train = image_dataset_from_directory(\n",
    "    base_path + '/train',\n",
    "    image_size=(w,h),\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    validation_split = 0.2,\n",
    "    subset= 'training',\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val = image_dataset_from_directory(\n",
    "    base_path + '/train',\n",
    "    image_size=(w,h),\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    validation_split = 0.2,\n",
    "    subset= 'validation',\n",
    "    label_mode='categorical'\n",
    ")\n",
    "    \n",
    "test = image_dataset_from_directory(\n",
    "    base_path + '/test',\n",
    "    image_size=(w,h),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical',\n",
    "    shuffle= False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4442f94-59a0-49d2-85f2-8e338738b62a",
   "metadata": {},
   "source": [
    "## EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0010fb-d327-4f1d-821d-32a83338dfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-b0 (Function  (None, 2, 2, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,084,695\n",
      "Trainable params: 6,023,831\n",
      "Non-trainable params: 60,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "effnet = Sequential()\n",
    "\n",
    "effnet_pretrained = EfficientNetV2B0(\n",
    "    input_shape= (h,w,3),\n",
    "    weights='imagenet',    \n",
    "    include_top=False,\n",
    "    include_preprocessing = True,\n",
    "    classifier_activation='softmax'\n",
    "    )\n",
    "\n",
    "\n",
    "effnet_pretrained.trainable = True\n",
    "\n",
    "effnet.add(effnet_pretrained)\n",
    "\n",
    "effnet.add(GlobalAveragePooling2D())\n",
    "effnet.add(Dense(128, activation='relu'))\n",
    "effnet.add(BatchNormalization())\n",
    "effnet.add(Dropout(0.5))\n",
    "\n",
    "effnet.add(Dense(7, activation='softmax'))\n",
    "effnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8607975-dede-4383-a3f4-423876899690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "effnet.compile(\n",
    "    optimizer= 'adam', \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc',\n",
    "               metrics.Precision(),\n",
    "               metrics.Recall(),\n",
    "               metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e89fc4e-8c06-43d7-b84d-ad3a05d98967",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience = 10,\n",
    "                   monitor = 'val_loss',\n",
    "                   mode = 'min')\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                       factor = 0.3,\n",
    "                       patience = 2,\n",
    "                       min_delta = 0.0001,\n",
    "                       verbose = 1)\n",
    "\n",
    "ck = ModelCheckpoint('../../Models/effnet.h5',\n",
    "                    save_best_only = True,\n",
    "                    monitor = 'val_acc',\n",
    "                    mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6bbedbf-ab55-4602-a436-6c70a0ca7d7b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1263/1263 [==============================] - 138s 109ms/step - loss: 1.3322 - acc: 0.4896 - precision: 0.7264 - recall: 0.2902 - auc: 0.8447 - val_loss: 1.1139 - val_acc: 0.5697 - val_precision: 0.8081 - val_recall: 0.3549 - val_auc: 0.8959 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1263/1263 [==============================] - 132s 105ms/step - loss: 1.1309 - acc: 0.5700 - precision: 0.7428 - recall: 0.4007 - auc: 0.8911 - val_loss: 1.0569 - val_acc: 0.5908 - val_precision: 0.7854 - val_recall: 0.4049 - val_auc: 0.9056 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1263/1263 [==============================] - 132s 105ms/step - loss: 1.0270 - acc: 0.6137 - precision: 0.7555 - recall: 0.4704 - auc: 0.9111 - val_loss: 1.0505 - val_acc: 0.6011 - val_precision: 0.7410 - val_recall: 0.4647 - val_auc: 0.9068 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1263/1263 [==============================] - 132s 104ms/step - loss: 0.9373 - acc: 0.6519 - precision: 0.7689 - recall: 0.5279 - auc: 0.9262 - val_loss: 1.0720 - val_acc: 0.6006 - val_precision: 0.7145 - val_recall: 0.4907 - val_auc: 0.9059 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.8439 - acc: 0.6891 - precision: 0.7850 - recall: 0.5885 - auc: 0.9402\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "1263/1263 [==============================] - 131s 104ms/step - loss: 0.8439 - acc: 0.6891 - precision: 0.7850 - recall: 0.5885 - auc: 0.9402 - val_loss: 1.0858 - val_acc: 0.5994 - val_precision: 0.6965 - val_recall: 0.5114 - val_auc: 0.9059 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1263/1263 [==============================] - 133s 106ms/step - loss: 0.5785 - acc: 0.7885 - precision: 0.8498 - recall: 0.7304 - auc: 0.9715 - val_loss: 1.1399 - val_acc: 0.6295 - val_precision: 0.6822 - val_recall: 0.5897 - val_auc: 0.9123 - lr: 3.0000e-04\n",
      "Epoch 7/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.4155 - acc: 0.8511 - precision: 0.8876 - recall: 0.8182 - auc: 0.9846\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "1263/1263 [==============================] - 134s 106ms/step - loss: 0.4155 - acc: 0.8511 - precision: 0.8876 - recall: 0.8182 - auc: 0.9846 - val_loss: 1.2885 - val_acc: 0.6237 - val_precision: 0.6581 - val_recall: 0.5965 - val_auc: 0.9032 - lr: 3.0000e-04\n",
      "Epoch 8/50\n",
      "1263/1263 [==============================] - 135s 107ms/step - loss: 0.2671 - acc: 0.9061 - precision: 0.9290 - recall: 0.8881 - auc: 0.9934 - val_loss: 1.4118 - val_acc: 0.6346 - val_precision: 0.6565 - val_recall: 0.6161 - val_auc: 0.8988 - lr: 9.0000e-05\n",
      "Epoch 9/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.1942 - acc: 0.9328 - precision: 0.9493 - recall: 0.9197 - auc: 0.9964\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "1263/1263 [==============================] - 134s 106ms/step - loss: 0.1942 - acc: 0.9328 - precision: 0.9493 - recall: 0.9197 - auc: 0.9964 - val_loss: 1.5343 - val_acc: 0.6289 - val_precision: 0.6473 - val_recall: 0.6154 - val_auc: 0.8904 - lr: 9.0000e-05\n",
      "Epoch 10/50\n",
      "1263/1263 [==============================] - 134s 106ms/step - loss: 0.1430 - acc: 0.9524 - precision: 0.9644 - recall: 0.9434 - auc: 0.9979 - val_loss: 1.5801 - val_acc: 0.6310 - val_precision: 0.6472 - val_recall: 0.6179 - val_auc: 0.8881 - lr: 2.7000e-05\n",
      "Epoch 11/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.1258 - acc: 0.9577 - precision: 0.9692 - recall: 0.9499 - auc: 0.9983\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "1263/1263 [==============================] - 135s 107ms/step - loss: 0.1258 - acc: 0.9577 - precision: 0.9692 - recall: 0.9499 - auc: 0.9983 - val_loss: 1.6343 - val_acc: 0.6288 - val_precision: 0.6455 - val_recall: 0.6169 - val_auc: 0.8846 - lr: 2.7000e-05\n",
      "Epoch 12/50\n",
      "1263/1263 [==============================] - 135s 107ms/step - loss: 0.1102 - acc: 0.9629 - precision: 0.9735 - recall: 0.9554 - auc: 0.9988 - val_loss: 1.6280 - val_acc: 0.6289 - val_precision: 0.6448 - val_recall: 0.6192 - val_auc: 0.8854 - lr: 8.1000e-06\n",
      "Epoch 13/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.1034 - acc: 0.9660 - precision: 0.9765 - recall: 0.9587 - auc: 0.9988\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "1263/1263 [==============================] - 138s 109ms/step - loss: 0.1034 - acc: 0.9660 - precision: 0.9765 - recall: 0.9587 - auc: 0.9988 - val_loss: 1.6830 - val_acc: 0.6274 - val_precision: 0.6424 - val_recall: 0.6170 - val_auc: 0.8817 - lr: 8.1000e-06\n"
     ]
    }
   ],
   "source": [
    "effnet_hist = effnet.fit(train, \n",
    "                validation_data = val,\n",
    "                epochs = 50,\n",
    "                callbacks = [es, lr, ck],\n",
    "                verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59aaf54-7f07-4960-9ccc-505e4faf3048",
   "metadata": {},
   "source": [
    "The EfficientnetV2B0 model is the smallest Efficientnet Version 2 model. The model weights were initialized with `imagenet` weights that are given by the keras API. While the training loss and training accuracy were promising (low train loss of 0.1034 and high train accuracy of 96.60%) the validation scores depict the model is not performing so well on the validation set. The loss was much higher with 1.6830 and the validation accuracy was 62.74%. This is lower than our best performing custom CNN model, which has a Validation Accuracy score of 64.46%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2193f8e3-4237-4407-aee2-238ac7001eed",
   "metadata": {},
   "source": [
    "# EfficientNet model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a354cf-d153-4363-b0a1-c2fd5decc917",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet_2 = Sequential()\n",
    "\n",
    "effnet_pretrained = EfficientNetV2B0(\n",
    "    input_shape= (h,w,3),\n",
    "    weights='imagenet',    \n",
    "    include_top=False,\n",
    "    include_preprocessing = True,\n",
    "    classifier_activation='softmax'\n",
    "    )\n",
    "\n",
    "\n",
    "effnet_pretrained.trainable = True\n",
    "\n",
    "effnet_2.add(data_augmentation)\n",
    "effnet_2.add(effnet_pretrained)\n",
    "\n",
    "effnet_2.add(GlobalAveragePooling2D())\n",
    "\n",
    "effnet_2.add(Dense(256, activation='relu'))\n",
    "effnet_2.add(BatchNormalization())\n",
    "effnet_2.add(Dropout(0.5))\n",
    "\n",
    "effnet_2.add(Dense(7, activation='softmax'))\n",
    "effnet_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7360e9ad-0c61-4aee-87cf-5c13ad35bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "effnet_2.compile(\n",
    "    optimizer= 'adam', \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc',\n",
    "               metrics.Precision(),\n",
    "               metrics.Recall(),\n",
    "               metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e2d76f52-f695-424b-b0b2-8036cf8a2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience = 10,\n",
    "                   monitor = 'val_loss',\n",
    "                   mode = 'min')\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                       factor = 0.4,\n",
    "                       patience = 2,\n",
    "                       min_delta = 0.0001,\n",
    "                       verbose = 1)\n",
    "\n",
    "ck = ModelCheckpoint('../../Models/effnet_2.h5',\n",
    "                    save_best_only = True,\n",
    "                    monitor = 'val_acc',\n",
    "                    mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a415759-87d3-4a5d-b725-26cb341f4d6a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1263/1263 [==============================] - 427s 301ms/step - loss: 1.7730 - acc: 0.3316 - precision_49: 0.5948 - recall_49: 0.1310 - auc_49: 0.7080 - val_loss: 1.4604 - val_acc: 0.4361 - val_precision_49: 0.7914 - val_recall_49: 0.1905 - val_auc_49: 0.8069 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1263/1263 [==============================] - 216s 171ms/step - loss: 1.4613 - acc: 0.4372 - precision_49: 0.7161 - recall_49: 0.2185 - auc_49: 0.8085 - val_loss: 1.3749 - val_acc: 0.4698 - val_precision_49: 0.7630 - val_recall_49: 0.2261 - val_auc_49: 0.8335 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1263/1263 [==============================] - 209s 165ms/step - loss: 1.3659 - acc: 0.4761 - precision_49: 0.7233 - recall_49: 0.2656 - auc_49: 0.8355 - val_loss: 1.3814 - val_acc: 0.4750 - val_precision_49: 0.7702 - val_recall_49: 0.2515 - val_auc_49: 0.8306 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1263/1263 [==============================] - 215s 170ms/step - loss: 1.3216 - acc: 0.4939 - precision_49: 0.7239 - recall_49: 0.2878 - auc_49: 0.8473 - val_loss: 1.2790 - val_acc: 0.5082 - val_precision_49: 0.7307 - val_recall_49: 0.2984 - val_auc_49: 0.8585 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1263/1263 [==============================] - 206s 163ms/step - loss: 1.2824 - acc: 0.5075 - precision_49: 0.7328 - recall_49: 0.3072 - auc_49: 0.8569 - val_loss: 1.2295 - val_acc: 0.5287 - val_precision_49: 0.7798 - val_recall_49: 0.3173 - val_auc_49: 0.8689 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1263/1263 [==============================] - 211s 167ms/step - loss: 1.2472 - acc: 0.5191 - precision_49: 0.7372 - recall_49: 0.3236 - auc_49: 0.8651 - val_loss: 1.2343 - val_acc: 0.5353 - val_precision_49: 0.7447 - val_recall_49: 0.3256 - val_auc_49: 0.8684 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 1.2307 - acc: 0.5285 - precision_49: 0.7406 - recall_49: 0.3356 - auc_49: 0.8693\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "1263/1263 [==============================] - 202s 160ms/step - loss: 1.2307 - acc: 0.5285 - precision_49: 0.7406 - recall_49: 0.3356 - auc_49: 0.8693 - val_loss: 1.2597 - val_acc: 0.5187 - val_precision_49: 0.7338 - val_recall_49: 0.3346 - val_auc_49: 0.8621 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1263/1263 [==============================] - 212s 167ms/step - loss: 1.1295 - acc: 0.5667 - precision_49: 0.7556 - recall_49: 0.3851 - auc_49: 0.8909 - val_loss: 1.2092 - val_acc: 0.5497 - val_precision_49: 0.7294 - val_recall_49: 0.3707 - val_auc_49: 0.8744 - lr: 3.0000e-04\n",
      "Epoch 9/50\n",
      "1263/1263 [==============================] - 207s 164ms/step - loss: 1.0910 - acc: 0.5825 - precision_49: 0.7580 - recall_49: 0.4103 - auc_49: 0.8986 - val_loss: 1.1464 - val_acc: 0.5653 - val_precision_49: 0.7413 - val_recall_49: 0.3909 - val_auc_49: 0.8877 - lr: 3.0000e-04\n",
      "Epoch 10/50\n",
      "1263/1263 [==============================] - 202s 160ms/step - loss: 1.0722 - acc: 0.5861 - precision_49: 0.7545 - recall_49: 0.4191 - auc_49: 0.9022 - val_loss: 1.1387 - val_acc: 0.5673 - val_precision_49: 0.7427 - val_recall_49: 0.4028 - val_auc_49: 0.8897 - lr: 3.0000e-04\n",
      "Epoch 11/50\n",
      "1263/1263 [==============================] - 211s 167ms/step - loss: 1.0580 - acc: 0.5928 - precision_49: 0.7615 - recall_49: 0.4317 - auc_49: 0.9048 - val_loss: 1.1276 - val_acc: 0.5724 - val_precision_49: 0.7332 - val_recall_49: 0.4163 - val_auc_49: 0.8919 - lr: 3.0000e-04\n",
      "Epoch 12/50\n",
      "1263/1263 [==============================] - 202s 159ms/step - loss: 1.0375 - acc: 0.6015 - precision_49: 0.7598 - recall_49: 0.4465 - auc_49: 0.9087 - val_loss: 1.1587 - val_acc: 0.5687 - val_precision_49: 0.7249 - val_recall_49: 0.4182 - val_auc_49: 0.8863 - lr: 3.0000e-04\n",
      "Epoch 13/50\n",
      "1263/1263 [==============================] - 206s 163ms/step - loss: 1.0268 - acc: 0.6073 - precision_49: 0.7660 - recall_49: 0.4538 - auc_49: 0.9106 - val_loss: 1.1087 - val_acc: 0.5811 - val_precision_49: 0.7258 - val_recall_49: 0.4448 - val_auc_49: 0.8964 - lr: 3.0000e-04\n",
      "Epoch 14/50\n",
      "1263/1263 [==============================] - 223s 176ms/step - loss: 1.0158 - acc: 0.6114 - precision_49: 0.7651 - recall_49: 0.4596 - auc_49: 0.9125 - val_loss: 1.0791 - val_acc: 0.5921 - val_precision_49: 0.7334 - val_recall_49: 0.4528 - val_auc_49: 0.9014 - lr: 3.0000e-04\n",
      "Epoch 15/50\n",
      "1263/1263 [==============================] - 221s 175ms/step - loss: 1.0028 - acc: 0.6159 - precision_49: 0.7633 - recall_49: 0.4676 - auc_49: 0.9149 - val_loss: 1.0827 - val_acc: 0.5962 - val_precision_49: 0.7300 - val_recall_49: 0.4619 - val_auc_49: 0.9015 - lr: 3.0000e-04\n",
      "Epoch 16/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.9927 - acc: 0.6189 - precision_49: 0.7658 - recall_49: 0.4709 - auc_49: 0.9167\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "1263/1263 [==============================] - 216s 171ms/step - loss: 0.9927 - acc: 0.6189 - precision_49: 0.7658 - recall_49: 0.4709 - auc_49: 0.9167 - val_loss: 1.1359 - val_acc: 0.5724 - val_precision_49: 0.7168 - val_recall_49: 0.4398 - val_auc_49: 0.8913 - lr: 3.0000e-04\n",
      "Epoch 17/50\n",
      "1263/1263 [==============================] - 236s 187ms/step - loss: 0.9563 - acc: 0.6329 - precision_49: 0.7761 - recall_49: 0.4921 - auc_49: 0.9227 - val_loss: 1.1323 - val_acc: 0.5800 - val_precision_49: 0.7123 - val_recall_49: 0.4590 - val_auc_49: 0.8935 - lr: 9.0000e-05\n",
      "Epoch 18/50\n",
      "1263/1263 [==============================] - 228s 181ms/step - loss: 0.9408 - acc: 0.6394 - precision_49: 0.7759 - recall_49: 0.5029 - auc_49: 0.9253 - val_loss: 1.0751 - val_acc: 0.5954 - val_precision_49: 0.7337 - val_recall_49: 0.4649 - val_auc_49: 0.9031 - lr: 9.0000e-05\n",
      "Epoch 19/50\n",
      "1263/1263 [==============================] - 219s 173ms/step - loss: 0.9298 - acc: 0.6440 - precision_49: 0.7779 - recall_49: 0.5121 - auc_49: 0.9271 - val_loss: 1.0783 - val_acc: 0.5973 - val_precision_49: 0.7299 - val_recall_49: 0.4667 - val_auc_49: 0.9027 - lr: 9.0000e-05\n",
      "Epoch 20/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.9174 - acc: 0.6490 - precision_49: 0.7811 - recall_49: 0.5188 - auc_49: 0.9290\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "1263/1263 [==============================] - 218s 173ms/step - loss: 0.9174 - acc: 0.6490 - precision_49: 0.7811 - recall_49: 0.5188 - auc_49: 0.9290 - val_loss: 1.1142 - val_acc: 0.5881 - val_precision_49: 0.7205 - val_recall_49: 0.4664 - val_auc_49: 0.8969 - lr: 9.0000e-05\n",
      "Epoch 21/50\n",
      "1263/1263 [==============================] - 204s 161ms/step - loss: 0.9045 - acc: 0.6529 - precision_49: 0.7841 - recall_49: 0.5261 - auc_49: 0.9310 - val_loss: 1.0924 - val_acc: 0.5948 - val_precision_49: 0.7236 - val_recall_49: 0.4734 - val_auc_49: 0.9008 - lr: 2.7000e-05\n",
      "Epoch 22/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.9072 - acc: 0.6553 - precision_49: 0.7870 - recall_49: 0.5246 - auc_49: 0.9306\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "1263/1263 [==============================] - 210s 167ms/step - loss: 0.9072 - acc: 0.6553 - precision_49: 0.7870 - recall_49: 0.5246 - auc_49: 0.9306 - val_loss: 1.1115 - val_acc: 0.5898 - val_precision_49: 0.7148 - val_recall_49: 0.4681 - val_auc_49: 0.8975 - lr: 2.7000e-05\n",
      "Epoch 23/50\n",
      "1263/1263 [==============================] - 203s 161ms/step - loss: 0.8983 - acc: 0.6565 - precision_49: 0.7822 - recall_49: 0.5276 - auc_49: 0.9320 - val_loss: 1.0987 - val_acc: 0.5937 - val_precision_49: 0.7161 - val_recall_49: 0.4721 - val_auc_49: 0.8999 - lr: 8.1000e-06\n",
      "Epoch 24/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.8960 - acc: 0.6582 - precision_49: 0.7851 - recall_49: 0.5302 - auc_49: 0.9324\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "1263/1263 [==============================] - 205s 162ms/step - loss: 0.8960 - acc: 0.6582 - precision_49: 0.7851 - recall_49: 0.5302 - auc_49: 0.9324 - val_loss: 1.0750 - val_acc: 0.5961 - val_precision_49: 0.7282 - val_recall_49: 0.4771 - val_auc_49: 0.9036 - lr: 8.1000e-06\n",
      "Epoch 25/50\n",
      "1263/1263 [==============================] - 200s 159ms/step - loss: 0.8913 - acc: 0.6598 - precision_49: 0.7855 - recall_49: 0.5328 - auc_49: 0.9332 - val_loss: 1.0725 - val_acc: 0.5989 - val_precision_49: 0.7237 - val_recall_49: 0.4761 - val_auc_49: 0.9040 - lr: 2.4300e-06\n",
      "Epoch 26/50\n",
      "1263/1263 [==============================] - 202s 160ms/step - loss: 0.8945 - acc: 0.6606 - precision_49: 0.7839 - recall_49: 0.5324 - auc_49: 0.9325 - val_loss: 1.0827 - val_acc: 0.5978 - val_precision_49: 0.7244 - val_recall_49: 0.4754 - val_auc_49: 0.9023 - lr: 2.4300e-06\n",
      "Epoch 27/50\n",
      "1263/1263 [==============================] - ETA: 0s - loss: 0.8926 - acc: 0.6590 - precision_49: 0.7866 - recall_49: 0.5311 - auc_49: 0.9329\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
      "1263/1263 [==============================] - 201s 159ms/step - loss: 0.8926 - acc: 0.6590 - precision_49: 0.7866 - recall_49: 0.5311 - auc_49: 0.9329 - val_loss: 1.0813 - val_acc: 0.5986 - val_precision_49: 0.7217 - val_recall_49: 0.4821 - val_auc_49: 0.9032 - lr: 2.4300e-06\n",
      "Epoch 28/50\n",
      "1263/1263 [==============================] - 203s 161ms/step - loss: 0.8885 - acc: 0.6611 - precision_49: 0.7863 - recall_49: 0.5345 - auc_49: 0.9335 - val_loss: 1.0783 - val_acc: 0.5980 - val_precision_49: 0.7219 - val_recall_49: 0.4771 - val_auc_49: 0.9030 - lr: 7.2900e-07\n",
      "Epoch 29/50\n",
      " 984/1263 [======================>.......] - ETA: 17:42 - loss: 0.8978 - acc: 0.6564 - precision_49: 0.7805 - recall_49: 0.5295 - auc_49: 0.9321"
     ]
    }
   ],
   "source": [
    "effnet_2 = model7.fit(train, \n",
    "                validation_data = val,\n",
    "                epochs = 50,\n",
    "                callbacks = [es, lr, ck],\n",
    "                verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1d6b9-753b-45d0-bb3c-1f351a405406",
   "metadata": {},
   "source": [
    "The second efficientnet model was stopped during it's training as the val_accuracy was not improving and doing worse than the custom sequential model performance (highest val_acc = 64.63%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a93854-8d0a-410d-8482-3f0869d743e0",
   "metadata": {},
   "source": [
    "Moving forward, further analysis will be done on the custom CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3634f9ae-d427-4c7e-a431-1c392b856821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
